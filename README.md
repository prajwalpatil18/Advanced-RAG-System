# ğŸš€ Advanced RAG (Retrieval-Augmented Generation) System

A **production-ready Advanced RAG system** designed for scalable, reliable, and efficient AI-powered question answering over custom documents. The project is **containerized with Docker** and **orchestrated using Kubernetes (K8s)** to support horizontal scaling and real-world workloads.

This repository is suitable for **enterprise-grade AI applications**, hackathons, and production deployments.

![CI](https://github.com/prajwalpatil18/Advanced-RAG-System/actions/workflows/ci.yml/badge.svg)

---

## âœ¨ Key Features

* ğŸ“„ **Document Ingestion with PDFs** 
* ğŸ” **Vector-based Semantic Search** using embeddings
* ğŸ§  **LLM-powered Answer Generation** (RAG pipeline)
* âš¡ **Low-latency Retrieval** with chunking & metadata filtering
* ğŸ³ **Dockerized Application** for consistent deployments
* â˜¸ï¸ **Kubernetes-ready** for scalability and high availability
* ğŸ“ˆ **Stateless API Design** â€“ easy to scale horizontally
* ğŸ” **Environment-based Configuration** for secrets & keys

---

## ğŸ—ï¸ High-Level Architecture

```
User Query
   â”‚
   â–¼
API Service (FastAPI)
   â”‚
   â”œâ”€â”€â–º Retriever (Vector DB)
   â”‚        â””â”€â”€ Embeddings Store
   â”‚
   â””â”€â”€â–º LLM (Generation)
            â””â”€â”€ Context-aware Answer
```

Deployed as **containerized microservices**, managed via **Kubernetes Deployments & Services**.

---

## ğŸ§° Tech Stack

* **Backend**: Python, FastAPI
* **LLM Framework**: LangChain
* **Embeddings**: OpenAI / HuggingFace
* **Vector Store**: FAISS / Chroma / Pinecone *(configurable)*
* **Containerization**: Docker
* **Orchestration**: Kubernetes (K8s)
* **API Gateway**: FastAPI + Uvicorn
* **Cloud Ready**: AWS / GCP / Azure compatible

## ğŸ³ Docker Setup

### Build Image

```bash
docker build -t advanced-rag:latest .
```

### Run Container

```bash
docker run -p 8000:8000 --env-file .env advanced-rag:latest
```

API will be available at:

```
http://localhost:8000
```

---

## â˜¸ï¸ Kubernetes Deployment

### Apply Kubernetes Manifests

```bash
kubectl apply -f k8s/
```

### Verify Deployment

```bash
kubectl get pods
kubectl get services
```

### Scale the Application

```bash
kubectl scale deployment advanced-rag --replicas=3
```

---

## âš™ï¸ Environment Variables

Create a `.env` file based on `.env.example`:

```
OPENAI_API_KEY=your_api_key
EMBEDDING_MODEL=text-embedding-3-large
VECTOR_DB=faiss
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
```

---

## ğŸ” API Endpoints

### Health Check

```
GET /health
```

### Ask a Question

```
POST /chat
```

**Request Body**:

```json
{
  "query": "What is discussed in the uploaded document?"
}
```

**Response**:

```json
{
  "answer": "Generated answer based on retrieved context"
}
```

---

## ğŸ“ˆ Scalability & Production Readiness

* Stateless API â†’ Horizontal Pod Autoscaling
* External Vector DB support
* ConfigMaps & Secrets for secure config
* Ready for Load Balancers & Ingress

---

## ğŸ§ª Use Cases

* Enterprise Knowledge Base Q&A
* Healthcare / Legal Document Analysis
* Research Paper Search
* Internal Company Chatbots
* AI Assistants with Private Data

---

## ğŸ›£ï¸ Future Enhancements

* ğŸ” Authentication & Role-based Access
* ğŸ“Š Monitoring (Prometheus + Grafana)
* ğŸ§  Fine-tuned Models Integration
* ğŸ”„ Streaming Responses
* ğŸ§¾ Citation-based Answers

---

## ğŸ¤ Contributing

Contributions are welcome! Feel free to open issues or submit pull requests.

---

## ğŸ“œ License

This project is licensed under the **MIT License**.

---

## â­ Acknowledgements

* LangChain
* OpenAI / HuggingFace
* Kubernetes Community

---

If you find this project useful, donâ€™t forget to â­ the repository!
